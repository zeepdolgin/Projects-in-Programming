{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zeepdolgin/Projects-in-Programming/blob/main/Team_D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oQozdgVKyjB"
      },
      "source": [
        "Connecting to SQL server\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5paDw9FjPBG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41bd3d3e-1a23-466f-aeb2-9a8672d4bcaf"
      },
      "source": [
        "# Connect to our MySQL server.\n",
        "# If you do not have the library, you need to install it by typing in the shell:\n",
        "!sudo apt-get install python3-mysqldb\n",
        "!sudo pip3 install -U sqlalchemy sql_magic"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "Suggested packages:\n",
            "  default-mysql-server | virtual-mysql-server python-egenix-mxdatetime\n",
            "  python3-mysqldb-dbg\n",
            "The following NEW packages will be installed:\n",
            "  python3-mysqldb\n",
            "0 upgraded, 1 newly installed, 0 to remove and 14 not upgraded.\n",
            "Need to get 46.0 kB of archives.\n",
            "After this operation, 183 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-mysqldb amd64 1.3.10-1build1 [46.0 kB]\n",
            "Fetched 46.0 kB in 1s (66.9 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package python3-mysqldb.\n",
            "(Reading database ... 144865 files and directories currently installed.)\n",
            "Preparing to unpack .../python3-mysqldb_1.3.10-1build1_amd64.deb ...\n",
            "Unpacking python3-mysqldb (1.3.10-1build1) ...\n",
            "Setting up python3-mysqldb (1.3.10-1build1) ...\n",
            "Requirement already up-to-date: sqlalchemy in /usr/local/lib/python3.6/dist-packages (1.3.20)\n",
            "Collecting sql_magic\n",
            "  Downloading https://files.pythonhosted.org/packages/a6/a7/ccdc67278de3f34db5d484f9b6c59ad9a536beda4a5acad5ecb3b0932246/sql_magic-0.0.4-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: traitlets in /usr/local/lib/python3.6/dist-packages (from sql_magic) (4.3.3)\n",
            "Requirement already satisfied, skipping upgrade: sqlparse in /usr/local/lib/python3.6/dist-packages (from sql_magic) (0.4.1)\n",
            "Requirement already satisfied, skipping upgrade: ipython in /usr/local/lib/python3.6/dist-packages (from sql_magic) (5.5.0)\n",
            "Collecting findspark\n",
            "  Downloading https://files.pythonhosted.org/packages/fc/2d/2e39f9a023479ea798eed4351cd66f163ce61e00c717e03c37109f00c0f2/findspark-1.4.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: pandas in /usr/local/lib/python3.6/dist-packages (from sql_magic) (1.1.4)\n",
            "Requirement already satisfied, skipping upgrade: jupyter in /usr/local/lib/python3.6/dist-packages (from sql_magic) (1.0.0)\n",
            "Requirement already satisfied, skipping upgrade: decorator in /usr/local/lib/python3.6/dist-packages (from traitlets->sql_magic) (4.4.2)\n",
            "Requirement already satisfied, skipping upgrade: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets->sql_magic) (0.2.0)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from traitlets->sql_magic) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython->sql_magic) (0.7.5)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython->sql_magic) (50.3.2)\n",
            "Requirement already satisfied, skipping upgrade: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython->sql_magic) (0.8.1)\n",
            "Requirement already satisfied, skipping upgrade: pygments in /usr/local/lib/python3.6/dist-packages (from ipython->sql_magic) (2.6.1)\n",
            "Requirement already satisfied, skipping upgrade: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->sql_magic) (4.8.0)\n",
            "Requirement already satisfied, skipping upgrade: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython->sql_magic) (1.0.18)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->sql_magic) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->sql_magic) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from pandas->sql_magic) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: notebook in /usr/local/lib/python3.6/dist-packages (from jupyter->sql_magic) (5.3.1)\n",
            "Requirement already satisfied, skipping upgrade: qtconsole in /usr/local/lib/python3.6/dist-packages (from jupyter->sql_magic) (5.0.1)\n",
            "Requirement already satisfied, skipping upgrade: ipykernel in /usr/local/lib/python3.6/dist-packages (from jupyter->sql_magic) (4.10.1)\n",
            "Requirement already satisfied, skipping upgrade: ipywidgets in /usr/local/lib/python3.6/dist-packages (from jupyter->sql_magic) (7.5.1)\n",
            "Requirement already satisfied, skipping upgrade: nbconvert in /usr/local/lib/python3.6/dist-packages (from jupyter->sql_magic) (5.6.1)\n",
            "Requirement already satisfied, skipping upgrade: jupyter-console in /usr/local/lib/python3.6/dist-packages (from jupyter->sql_magic) (5.2.0)\n",
            "Requirement already satisfied, skipping upgrade: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->sql_magic) (0.6.0)\n",
            "Requirement already satisfied, skipping upgrade: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->sql_magic) (0.2.5)\n",
            "Requirement already satisfied, skipping upgrade: jupyter-client>=5.2.0 in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->sql_magic) (5.3.5)\n",
            "Requirement already satisfied, skipping upgrade: jinja2 in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->sql_magic) (2.11.2)\n",
            "Requirement already satisfied, skipping upgrade: Send2Trash in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->sql_magic) (1.5.0)\n",
            "Requirement already satisfied, skipping upgrade: terminado>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->sql_magic) (0.9.1)\n",
            "Requirement already satisfied, skipping upgrade: tornado>=4 in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->sql_magic) (5.1.1)\n",
            "Requirement already satisfied, skipping upgrade: jupyter-core>=4.4.0 in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->sql_magic) (4.7.0)\n",
            "Requirement already satisfied, skipping upgrade: nbformat in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->sql_magic) (5.0.8)\n",
            "Requirement already satisfied, skipping upgrade: qtpy in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter->sql_magic) (1.9.0)\n",
            "Requirement already satisfied, skipping upgrade: pyzmq>=17.1 in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter->sql_magic) (20.0.0)\n",
            "Requirement already satisfied, skipping upgrade: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->jupyter->sql_magic) (3.5.1)\n",
            "Requirement already satisfied, skipping upgrade: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->sql_magic) (0.6.0)\n",
            "Requirement already satisfied, skipping upgrade: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->sql_magic) (0.4.4)\n",
            "Requirement already satisfied, skipping upgrade: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->sql_magic) (3.2.1)\n",
            "Requirement already satisfied, skipping upgrade: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->sql_magic) (0.8.4)\n",
            "Requirement already satisfied, skipping upgrade: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->sql_magic) (0.3)\n",
            "Requirement already satisfied, skipping upgrade: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->sql_magic) (1.4.3)\n",
            "Requirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->notebook->jupyter->sql_magic) (1.1.1)\n",
            "Requirement already satisfied, skipping upgrade: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat->notebook->jupyter->sql_magic) (2.6.0)\n",
            "Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->jupyter->sql_magic) (20.4)\n",
            "Requirement already satisfied, skipping upgrade: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->jupyter->sql_magic) (0.5.1)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->bleach->nbconvert->jupyter->sql_magic) (2.4.7)\n",
            "Installing collected packages: findspark, sql-magic\n",
            "Successfully installed findspark-1.4.2 sql-magic-0.0.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqngtIiDjRuo"
      },
      "source": [
        "import sqlalchemy\n",
        "from sqlalchemy import create_engine\n",
        "\n",
        "conn_string = 'mysql://{user}:{password}@{host}/'.format(\n",
        "    host = 'db.ipeirotis.org',\n",
        "    user = 'student',\n",
        "    password = 'dwdstudent2015',\n",
        "    db = 'public')\n",
        "\n",
        "engine = create_engine(conn_string)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OljCjftKSdf"
      },
      "source": [
        "all_zip_in_case_needed = ['10001', '10002', '10003', '10004', '10005', '10006', '10007', '10008', '10009', '10010', '10011', '10012', '10013', '10014', '10016', '10017', '10018', '10019', '10020', '10021', '10022', '10023', '10024', '10025', '10026', '10027', '10028', '10029', '10030', '10031', '10032', '10033', '10034', '10035', '10036', '10037', '10038', '10039', '10040', '10041', '10043', '10044', '10045', '10055', '10060', '10065', '10069', '10075', '10080', '10081', '10087', '10090', '10101', '10102', '10103', '10104', '10105', '10106', '10107', '10108', '10109', '10110', '10111', '10112', '10113', '10114', '10115', '10116', '10117', '10118', '10119', '10120', '10121', '10122', '10123', '10124', '10125', '10126', '10128', '10129', '10130', '10131', '10132', '10133', '10138', '10150', '10151', '10152', '10153', '10154', '10155', '10156', '10157', '10158', '10159', '10160', '101612', '10163', '10164', '10165', '10166', '10167', '10168', '10169', '10170', '10171', '10172', '10173', '10174', '10175', '10176', '10177', '10178', '10179', '10185', '10199', '10203', '10211', '10212', '10213', '10242', '10249', '10256', '10258', '10259', '10260', '10261', '10265', '10268', '10269', '10270', '10271', '10272', '10273', '10274', '10275', '10276', '10277', '10278', '10279', '10280', '10281', '10282', '10285', '10286']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GR4RrrLKybc"
      },
      "source": [
        "# API calls as shown in Realtor API documentation\n",
        "import pandas as pd\n",
        "import requests\n",
        "import json\n",
        "\n",
        "url = \"https://realtor.p.rapidapi.com/properties/v2/list-for-sale\"\n",
        "df = pd.DataFrame(columns=['postal code','listing_id','address','neighborhood','latidude','longitude','bed','bath','size','broker name','property type','property sub type','price'])\n",
        "data_list = []\n",
        "\n",
        "list_of_zip_codes = ['10001','10002', '10003', '10004', '10005', '10006', '10007', '10009', '10010', '10011', '10012', '10013', '10014', '10016', '10017', '10018', '10019', '10021', '10022', '10023', '10024', '10025', '10026', '10027', '10028', '10029', '10030', '10031', '10032', '10033', '10034', '10035', '10036', '10037', '10038', '10039', '10040', '10044', '10065', '10069', '10075', '10128', '10172', '10280', '10282']\n",
        "\n",
        "# Each API response contains up to 200 properties, but no individual ZIP code has more than 200 properties for sale at the moment,\n",
        "# so we iterate through the zip codes in the list and make a new API call for each zip code, while filtering and recording the data into a pandas dataframe after each call.\n",
        "# Code might fail with this API key if it makes more than 500 calls per month\n",
        "\n",
        "\n",
        "for i in list_of_zip_codes:\n",
        "  querystring = {\"city\":\"New York City\",\"offset\":\"0\",\"state_code\":\"NY\",\"limit\":\"200\",\"postal_code\":i,\"sort\":\"sold_date\"}\n",
        "  headers = {\n",
        "      'x-rapidapi-key': \"239934955fmsh26f828ad8867cc7p1a166cjsnbc235583b967\",\n",
        "      'x-rapidapi-host': \"realtor.p.rapidapi.com\",\n",
        "      }\n",
        "  response = requests.request(\"GET\", url, headers=headers, params=querystring)\n",
        "  data_list.append(json.loads(response.text))\n",
        "\n",
        "# Data filters\n",
        "for data in data_list:\n",
        "  print(data)\n",
        "\n",
        "  if 'properties' in data:\n",
        "\n",
        "    if len(data['properties']) == 0:\n",
        "      data_address = \"0\"\n",
        "      data_bed = \"0\"\n",
        "      data_bath = \"0\"\n",
        "      data_size = \"0\"\n",
        "\n",
        "    else:\n",
        "      for x in data['properties']:\n",
        "        if 'beds'in x:\n",
        "          if x['beds'] == None:\n",
        "            data_bed = \"0\"\n",
        "          else:\n",
        "            data_bed = str(x['beds'])\n",
        "        else:\n",
        "          data_bed = \"0\"\n",
        "        if 'baths' in x:\n",
        "          if x['baths'] == None:\n",
        "            data_bath = \"0\"\n",
        "          else:\n",
        "            data_bath = str(x['baths'])\n",
        "        else:\n",
        "          data_bath = \"0\"\n",
        "        if  'address' in x:\n",
        "          if 'line' in x['address']:\n",
        "            if x['address']['line'] == None:\n",
        "              data_Address = \"0\"\n",
        "            else:\n",
        "              data_Address = str(x['address']['line'])\n",
        "          else:\n",
        "            data_Address = \"0\"\n",
        "          if 'postal_code' in x['address']:\n",
        "            if x['address']['postal_code'] == None:\n",
        "              data_zip = \"0\"\n",
        "            else:\n",
        "              data_zip = str(x['address']['postal_code'])\n",
        "          else:\n",
        "            data_zip = \"0\"\n",
        "          if 'lat' in x['address']:\n",
        "            if x['address']['lat'] == None:\n",
        "              data_lat = \"0\"\n",
        "            else:\n",
        "              data_lat = str(x['address']['lat'])\n",
        "          else:\n",
        "            data_lat = \"0\"\n",
        "          if 'lon' in x['address']:\n",
        "            if x['address']['lon'] == None:\n",
        "              data_lon = \"0\"\n",
        "            else:\n",
        "              data_lon = str(x['address']['lon'])\n",
        "          else:\n",
        "            data_lon = \"0\"\n",
        "          if 'neighborhood_name' in x['address']:\n",
        "            if x['address']['neighborhood_name'] == None:\n",
        "              data_neighborhood = \"0\"\n",
        "            else:\n",
        "              data_neighborhood = str(x['address']['neighborhood_name'])\n",
        "          else:\n",
        "            data_neighborhood = \"0\"\n",
        "        if  'name' in x['branding']['listing_office']['list_item']:\n",
        "          if x['branding']['listing_office']['list_item']['name'] == None:\n",
        "              data_broker_name = \"0\"\n",
        "          else:\n",
        "              data_broker_name = str(x['branding']['listing_office']['list_item']['name'])\n",
        "        else:\n",
        "            data_broker_name = \"0\"\n",
        "        if 'listing_id' in x:\n",
        "          if x['listing_id'] == None:\n",
        "            data_id = \"0\"\n",
        "          else:\n",
        "            data_id = str(x['listing_id'])\n",
        "        else:\n",
        "          data_id = \"0\"\n",
        "        if 'price' in x:\n",
        "          if x['price'] == None:\n",
        "            data_price = \"0\"\n",
        "          else:\n",
        "            data_price = str(x['price'])\n",
        "        else:\n",
        "          data_price = \"0\"\n",
        "        if 'prop_sub_type' in x:\n",
        "          if x['prop_sub_type'] == None:\n",
        "            data_sub_type = \"0\"\n",
        "          else:\n",
        "            data_sub_type = str(x['prop_sub_type'])\n",
        "        else:\n",
        "          data_sub_type = \"0\"\n",
        "        if 'prop_type' in x:\n",
        "          if x['prop_type'] == None:\n",
        "            data_type = \"0\"\n",
        "          else:\n",
        "            data_type = str(x['prop_type'])\n",
        "        else:\n",
        "          data_type = \"0\"\n",
        "        if 'building_size' in x:\n",
        "          if 'size' in x['building_size']:\n",
        "            if x['building_size']['size'] == None:\n",
        "              data_size = \"0\"\n",
        "            else:\n",
        "              data_size = str(x['building_size']['size'])\n",
        "          else:\n",
        "            data_size = \"0\"\n",
        "        else:\n",
        "          data_size = \"0\"\n",
        "# recording the response into the dataframe\n",
        "        df = df.append({'postal code': data_zip,\n",
        "                        'listing_id': data_id,\n",
        "                        'address': data_Address,\n",
        "                        'neighborhood': data_neighborhood,\n",
        "                        'latitude': data_lat,\n",
        "                        'longitude': data_lon,\n",
        "                        'bed': data_bed,\n",
        "                        'bath' : data_bath,\n",
        "                        'size' : data_size,\n",
        "                        'broker name': data_broker_name,\n",
        "                        'property type': data_type,\n",
        "                        'property sub type': data_sub_type,\n",
        "                        'price': data_price}, ignore_index=True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXrC9WV5AE0L"
      },
      "source": [
        "# recording the dataframe to SQL database\n",
        "\n",
        "df.to_sql(name='Team_D', # name the table \"inspections\"\n",
        "                   con=engine, # use the connection to MySQL created earlier\n",
        "                   if_exists='replace', # if the table is already there, replace it\n",
        "                   index=False, # do not write the index column in the database\n",
        "                   chunksize=1000 # write 1000 lines at a time\n",
        ")\n",
        "\n",
        "# if code above does not work, use this:\n",
        "# df.to_csv('real_data.csv', index = list_of_zip_codes)\n",
        "# to save the dataframe to a CSV file and upload it to SQL manually."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "poeTrDtHKyoz"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwfvukssKyrf"
      },
      "source": []
    }
  ]
}